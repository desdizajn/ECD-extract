#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ECD (Electronic Customs Declaration) PDF Extractor - Generic Version
–ì–µ–Ω–µ—Ä–∏—á–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞ –∑–∞ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ –±–∏–ª–æ –∫–æ—ò –ï–¶–î PDF –¥–æ–∫—É–º–µ–Ω—Ç
"""

import fitz  # PyMuPDF
import re
import json
from typing import Dict, List, Optional, Any, Tuple
import pytesseract
from pdf2image import convert_from_path
from PIL import Image, ImageEnhance, ImageFilter
import os


class ECDExtractorGeneric:
    """–ì–µ–Ω–µ—Ä–∏—á–∫–∞ –∫–ª–∞—Å–∞ –∑–∞ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ –ï–¶–î PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏"""
    
    def __init__(self, pdf_path: str, verbose: bool = False):
        self.pdf_path = pdf_path
        self.text = ""
        self.lines = []
        self.data_start_index = -1
        self.verbose = verbose
        self.data = {
            "HEAHEA": {},
            "TRAEXPEX1": {},
            "TRACONCE1": {},
            "SEAINFSLI": {
                "SeaNumSLI2": None,
                "SEAIDSID": [{"SeaIdeSID1": ""}]
            },
            "GOOITEGDS": []
        }
    
    def is_scanned_pdf(self) -> bool:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä–∞ –¥–∞–ª–∏ PDF –µ —Å–∫–µ–Ω–∏—Ä–∞–Ω (–Ω–µ–º–∞ —Ç–µ–∫—Å—Ç) –∏–ª–∏ –∏–º–∞ –≤–≥—Ä–∞–¥–µ–Ω —Ç–µ–∫—Å—Ç"""
        try:
            doc = fitz.open(self.pdf_path)
            total_chars = 0
            total_pages = len(doc)
            
            # –ü—Ä–æ–≤–µ—Ä–∏ –≥–∏ –ø—Ä–≤–∏—Ç–µ –Ω–µ–∫–æ–ª–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü–∏
            for page_num in range(min(3, total_pages)):
                page = doc[page_num]
                text = page.get_text().strip()
                total_chars += len(text)
            
            doc.close()
            
            # –ê–∫–æ –∏–º–∞ –ø–æ–º–∞–ª–∫—É –æ–¥ 100 –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏ –Ω–∞ –ø—Ä–≤–∏—Ç–µ 3 —Å—Ç—Ä–∞–Ω–∏—Ü–∏, –≤–µ—Ä–æ—ò–∞—Ç–Ω–æ –µ —Å–∫–µ–Ω–∏—Ä–∞–Ω
            if self.verbose:
                print(f"   –ë—Ä–æ—ò –Ω–∞ –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏ –≤–æ –ø—Ä–≤–∏—Ç–µ {min(3, total_pages)} —Å—Ç—Ä–∞–Ω–∏—Ü–∏: {total_chars}")
            
            is_scanned = total_chars < 100
            if self.verbose:
                if is_scanned:
                    print("   ‚ö†Ô∏è  –î–µ—Ç–µ–∫—Ç–∏—Ä–∞–Ω —Å–∫–µ–Ω–∏—Ä–∞–Ω –¥–æ–∫—É–º–µ–Ω—Ç - —ú–µ —Å–µ –∫–æ—Ä–∏—Å—Ç–∏ OCR")
                else:
                    print("   ‚úÖ –î–µ—Ç–µ–∫—Ç–∏—Ä–∞–Ω —Ç–µ–∫—Å—Ç—É–∞–ª–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç")
            
            return is_scanned
            
        except Exception as e:
            if self.verbose:
                print(f"   ‚ö†Ô∏è  –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –¥–µ—Ç–µ–∫—Ü–∏—ò–∞: {e}")
            return False
    
    def preprocess_image_for_ocr(self, image):
        """–ü–æ–¥–æ–±—Ä—É–≤–∞—ö–µ –Ω–∞ —Å–ª–∏–∫–∞—Ç–∞ –∑–∞ –ø–æ–¥–æ–±—Ä–∞ OCR —Ç–æ—á–Ω–æ—Å—Ç"""
        # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞—ò –≤–æ grayscale
        if image.mode != 'L':
            image = image.convert('L')
        
        # 2. –ó–≥–æ–ª–µ–º–∏ —ò–∞ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç–∞
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(2.0)
        
        # 3. –ó–≥–æ–ª–µ–º–∏ —ò–∞ –æ—Å—Ç—Ä–∏–Ω–∞ta
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(1.5)
        
        # 4. Apply threshold –∑–∞ –ø–æ–¥–æ–±–∞—Ä –∫–æ–Ω—Ç—Ä–∞—Å—Ç (binarization)
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞—ò –≤–æ —Ü—Ä–Ω–æ-–±–µ–ª–æ
        threshold = 180
        image = image.point(lambda x: 0 if x < threshold else 255, '1')
        
        return image
    
    def extract_text_with_ocr(self) -> str:
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ —Ç–µ–∫—Å—Ç –æ–¥ —Å–∫–µ–Ω–∏—Ä–∞–Ω PDF –∫–æ—Ä–∏—Å—Ç–µ—ò—ú–∏ OCR (Tesseract) —Å–æ –º–∞–∫–µ–¥–æ–Ω—Å–∫–∏ —ò–∞–∑–∏–∫"""
        if self.verbose:
            print("   üîç –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞—ö–µ –Ω–∞ PDF –≤–æ —Å–ª–∏–∫–∏...")
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞—ò –≥–æ PDF –≤–æ —Å–ª–∏–∫–∏ (300 DPI –∑–∞ –ø–æ–¥–æ–±—Ä–∞ —Ç–æ—á–Ω–æ—Å—Ç)
            images = convert_from_path(self.pdf_path, dpi=300)
            
            if self.verbose:
                print(f"   üìÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–Ω–∏ {len(images)} —Å—Ç—Ä–∞–Ω–∏—Ü–∏")
                print("   üîé –ò–∑–≤—Ä—à—É–≤–∞—ö–µ –Ω–∞ OCR —Å–æ –º–∞–∫–µ–¥–æ–Ω—Å–∫–∏ —ò–∞–∑–∏–∫...")
            
            full_text = ""
            
            # –ò–∑–≤—Ä—à–∏ OCR –Ω–∞ —Å–µ–∫–æ—ò–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞
            for i, image in enumerate(images):
                if self.verbose:
                    print(f"   üìÉ –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {i+1}/{len(images)}...", end=" ")
                
                # Preprocessing –Ω–∞ —Å–ª–∏–∫–∞—Ç–∞ –∑–∞ –ø–æ–¥–æ–±—Ä–∞ —Ç–æ—á–Ω–æ—Å—Ç
                processed_image = self.preprocess_image_for_ocr(image)
                
                # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–∞ –∑–∞ Tesseract
                # --psm 6: –ü—Ä–µ—Ç–ø–æ—Å—Ç–∞–≤–∏ –±–ª–æ–∫ –Ω–∞ –µ–¥–Ω–∞–∫–≤–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–∞–Ω —Ç–µ–∫—Å—Ç
                # --oem 3: –ö–æ—Ä–∏—Å—Ç–∏ LSTM –º–æ–¥–µ–ª (–Ω–∞—ò–¥–æ–±—Ä–∞ —Ç–æ—á–Ω–æ—Å—Ç)
                custom_config = r'--oem 3 --psm 6'
                
                # –û–±–∏–¥–∏ —Å–µ —Å–æ –º–∞–∫–µ–¥–æ–Ω—Å–∫–∏+–∞–Ω–≥–ª–∏—Å–∫–∏ (mkd+eng) - –ù–ê–à–î–û–ë–†–û –∑–∞ –º–∞–∫–µ–¥–æ–Ω—Å–∫–∏ ECD
                try:
                    text = pytesseract.image_to_string(
                        processed_image, 
                        lang='mkd+eng',  # –ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏ + –∞–Ω–≥–ª–∏—Å–∫–∏
                        config=custom_config
                    )
                    if self.verbose:
                        char_count = len(text.strip())
                        print(f"({char_count} –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏ - mkd+eng)")
                except Exception as e:
                    # Fallback: –û–±–∏–¥–∏ —Å–µ —Å–æ —Å—Ä–ø—Å–∫–∏+–∞–Ω–≥–ª–∏—Å–∫–∏
                    if self.verbose:
                        print(f"\n      ‚ö†Ô∏è  Fallback –Ω–∞ srp+eng...")
                    try:
                        text = pytesseract.image_to_string(
                            processed_image, 
                            lang='srp+eng',
                            config=custom_config
                        )
                        if self.verbose:
                            char_count = len(text.strip())
                            print(f"      ({char_count} –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏ - srp+eng)")
                    except:
                        # –ü–æ—Å–ª–µ–¥–µ–Ω fallback: —Å–∞–º–æ –∞–Ω–≥–ª–∏—Å–∫–∏
                        text = pytesseract.image_to_string(
                            processed_image, 
                            lang='eng',
                            config=custom_config
                        )
                        if self.verbose:
                            char_count = len(text.strip())
                            print(f"      ({char_count} –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏ - eng)")
                
                full_text += text + "\n"
            
            if self.verbose:
                print(f"   ‚úÖ OCR –∑–∞–≤—Ä—à–µ–Ω - –≤–∫—É–ø–Ω–æ {len(full_text)} –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏")
            
            self.text = full_text
            self.lines = full_text.split('\n')
            return full_text
            
        except Exception as e:
            if self.verbose:
                print(f"   ‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ OCR: {e}")
            raise
    
    def extract_text_from_pdf(self) -> str:
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ —Ç–µ–∫—Å—Ç –æ–¥ PDF –¥–æ–∫—É–º–µ–Ω—Ç (–∞–≤—Ç–æ–º–∞—Ç—Å–∫–∏ –¥–µ—Ç–µ–∫—Ç–∏—Ä–∞ –¥–∞–ª–∏ —Ç—Ä–µ–±–∞ OCR)"""
        # –î–µ—Ç–µ–∫—Ç–∏—Ä–∞—ò –¥–∞–ª–∏ –µ —Å–∫–µ–Ω–∏—Ä–∞–Ω
        if self.is_scanned_pdf():
            # –ö–æ—Ä–∏—Å—Ç–∏ OCR
            return self.extract_text_with_ocr()
        else:
            # –ö–æ—Ä–∏—Å—Ç–∏ –≤–≥—Ä–∞–¥–µ–Ω —Ç–µ–∫—Å—Ç
            doc = fitz.open(self.pdf_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            self.text = text
            self.lines = text.split('\n')
            return text
    
    def find_data_section(self):
        """–ù–∞–æ—ì–∞ —ò–∞ —Å–µ–∫—Ü–∏—ò–∞—Ç–∞ —Å–æ –≤–∏—Å—Ç–∏–Ω—Å–∫–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏ (–Ω–µ —à–∞–±–ª–æ–Ω–æ—Ç)"""
        # –ë–∞—Ä–∞—ò —ò–∞ –ª–∏–Ω–∏—ò–∞—Ç–∞ —Å–æ '341' –∏–ª–∏ –¥—Ä—É–≥ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–æ–Ω–µ–Ω –∫–æ–¥
        # –ü–æ–¥–∞—Ç–æ—Ü–∏—Ç–µ –ø–æ—á–Ω—É–≤–∞–∞—Ç –ø–æ—Å–ª–µ –ø—Ä–≤–∞—Ç–∞ –ø–æ—ò–∞–≤–∞ –Ω–∞ —à–∞–±–ª–æ–Ω–æ—Ç
        # –ú–∞—Ä–∫–µ—Ä –µ 'EXMK', 'IMMK' –∏–ª–∏ —Å–ª–∏—á–Ω–æ (–º–æ–∂–µ –¥–∞ –±–∏–¥–µ –≤–æ —Å—Ä–µ–¥–∏–Ω–∞—Ç–∞ –Ω–∞ –ª–∏–Ω–∏—ò–∞)
        for i, line in enumerate(self.lines):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞ —Ç–æ—á–µ–Ω match (—Å–∞–º–æ—Å—Ç–æ—ò–Ω–∞ –ª–∏–Ω–∏—ò–∞)
            if re.match(r'^(EX|IM)[A-Z]{2}$', line.strip()):
                self.data_start_index = i
                if self.verbose:
                    print(f"   –ü–æ—á–µ—Ç–æ–∫ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –Ω–∞ –ª–∏–Ω–∏—ò–∞: {i}")
                return i
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞ match –≤–æ —Å—Ä–µ–¥–∏–Ω–∞—Ç–∞ –Ω–∞ –ª–∏–Ω–∏—ò–∞—Ç–∞ (–∑–∞ OCR —Ç–µ–∫—Å—Ç)
            if re.search(r'\b(EX|IM)[A-Z]{2}\b', line):
                self.data_start_index = i
                if self.verbose:
                    print(f"   –ü–æ—á–µ—Ç–æ–∫ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –Ω–∞ –ª–∏–Ω–∏—ò–∞: {i} (OCR –¥–µ—Ç–µ–∫—Ü–∏—ò–∞)")
                return i
        
        # –ê–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ, –±–∞—Ä–∞—ò 'LRN :' –∏–ª–∏ 'LRN:' –∏ –æ–¥–∏ –Ω–∞–∑–∞–¥
        for i, line in enumerate(self.lines):
            if 'LRN :' in line or 'LRN:' in line or 'LRN ' in line:
                # –û–¥–∏ –Ω–∞–∑–∞–¥ –æ–∫–æ–ª—É 2-5 –ª–∏–Ω–∏–∏ (–∑–∞ OCR –¥–æ–∫—É–º–µ–Ω—Ç–∏ LRN –µ –Ω–∞ –≤—Ä–≤–æ—Ç)
                self.data_start_index = max(0, i - 2)
                if self.verbose:
                    print(f"   –ü–æ—á–µ—Ç–æ–∫ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –Ω–∞ –ª–∏–Ω–∏—ò–∞: {self.data_start_index} (LRN –º–∞—Ä–∫–µ—Ä)")
                return self.data_start_index
                return self.data_start_index
        
        # –ê–∫–æ –Ω–µ –≥–æ –Ω–∞—ò–¥–æ–≤–º–µ, –∑–µ–º–∏ –æ–¥ –ª–∏–Ω–∏—ò–∞ 80
        self.data_start_index = 80
        return 80
    
    def find_next_nonempty_line(self, start_index: int, max_search: int = 10) -> Tuple[int, str]:
        """–ù–∞–æ—ì–∞ —ò–∞ —Å–ª–µ–¥–Ω–∞—Ç–∞ –Ω–µ–ø—Ä–∞–∑–Ω–∞ –ª–∏–Ω–∏—ò–∞"""
        for i in range(start_index, min(len(self.lines), start_index + max_search)):
            line = self.lines[i].strip()
            if line and line not in ['–∞', '–±', '–≤']:  # –ò–≥–Ω–æ—Ä–∏—Ä–∞—ò –º–∞—Ä–∫–µ—Ä–∏
                return i, line
        return -1, ""
    
    def get_line_safe(self, index: int) -> str:
        """–í—Ä–∞—ú–∞ –ª–∏–Ω–∏—ò–∞ –∏–ª–∏ –ø—Ä–∞–∑–µ–Ω string –∞–∫–æ –µ –Ω–∞–¥–≤–æ—Ä –æ–¥ –æ–ø—Å–µ–≥"""
        if 0 <= index < len(self.lines):
            return self.lines[index].strip()
        return ""
    
    def extract_heahea(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ HEAHEA —Å–µ–∫—Ü–∏—ò–∞—Ç–∞"""
        # Total gross mass - –±—Ä–æ—ò –ø—Ä–µ–¥ "KGM"
        for i, line in enumerate(self.lines):
            if line.strip() == 'KGM':
                mass_line = self.get_line_safe(i - 1)
                if mass_line.isdigit():
                    self.data["HEAHEA"]["TotGroMasHEA307"] = int(mass_line)
                break
        
        # Identity of means of transport - –±–∞—Ä–∞—ò pattern XX1234YY –∏–ª–∏ XX1234YY/XX1234YY
        vehicle_pattern = r'^([A-Z]{2}\d{4}[A-Z]{2}(?:/[A-Z]{2}\d{4}[A-Z]{2})?)$'
        for i in range(self.data_start_index, min(len(self.lines), self.data_start_index + 50)):
            line = self.lines[i].strip()
            match = re.match(vehicle_pattern, line)
            if match:
                self.data["HEAHEA"]["IdeOfMeaOfTraAtDHEA78"] = match.group(1)
                # –°–ª–µ–¥–Ω–∞—Ç–∞ –ª–∏–Ω–∏—ò–∞ –µ –æ–±–∏—á–Ω–æ –Ω–∞—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç–∞
                next_idx, next_line = self.find_next_nonempty_line(i + 1, 3)
                if next_line and re.match(r'^[A-Z]{2}$', next_line):
                    self.data["HEAHEA"]["NatOfMeaOfTraCroHEA87"] = next_line
                break
        
        # Mode of transport at the border - –±–∞—Ä–∞—ò –±—Ä–æ—ò –ø–æ–º–µ—ì—É 1-9 –∫–æ—ò –µ –æ–∫–æ–ª—É –≤–æ–∑–∏–ª–æ—Ç–æ
        # –û–±–∏—á–Ω–æ –µ –ø–æ—Å–ª–µ –∫–æ–Ω—Ç–µ—ò–Ω–µ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ—Ç –∏ –ø—Ä–µ–¥ –≤–∞–ª—É—Ç–∞—Ç–∞
        mode_candidates = []
        for i in range(self.data_start_index, min(len(self.lines), self.data_start_index + 50)):
            line = self.lines[i].strip()
            if line in ['1', '2', '3', '4', '5', '6', '7', '8', '9']:
                # –ü—Ä–æ–≤–µ—Ä–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç - –∞–∫–æ –µ –ø–æ—Å–ª–µ –∑–µ–º—ò–∞ –∫–æ–¥ –∏ –ø—Ä–µ–¥ –≤–∞–ª—É—Ç–∞
                prev_line = self.get_line_safe(i - 1)
                next_line = self.get_line_safe(i + 1)
                if re.match(r'^[A-Z]{2,3}$', prev_line) or 'EUR' in next_line or 'USD' in next_line:
                    mode_candidates.append(line)
        
        # –ó–µ–º–∏ —ò–∞ –Ω–∞—ò—á–µ—Å—Ç–∞—Ç–∞ –≤—Ä–µ–¥–Ω–æ—Å—Ç –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∞—Ç–∞
        if mode_candidates:
            self.data["HEAHEA"]["TraModAtBorHEA76"] = mode_candidates[-1]
        
        # Country of dispatch code - –±–∞—Ä–∞—ò MK –∏–ª–∏ –¥—Ä—É–≥ –∫–æ–¥ –≤–æ –ø–æ—á–µ—Ç–æ–∫–æ—Ç
        # –û–±–∏—á–Ω–æ –µ –ø–æ—Å–ª–µ –∏–º–µ—Ç–æ –Ω–∞ –∑–µ–º—ò–∞—Ç–∞
        for i in range(self.data_start_index, min(len(self.lines), self.data_start_index + 50)):
            line = self.lines[i].strip()
            if '–°–ï–í–ï–†–ù–ê –ú–ê–ö–ï–î–û–ù–ò–à–ê' in line or '–ú–ê–ö–ï–î–û–ù–ò–à–ê' in line or 'MACEDONIA' in line:
                # –°–ª–µ–¥–Ω–∞ –ª–∏–Ω–∏—ò–∞ –µ –æ–±–∏—á–Ω–æ –∫–æ–¥–æ—Ç
                next_idx, next_line = self.find_next_nonempty_line(i + 1, 3)
                if next_line and re.match(r'^[A-Z]{2}$', next_line):
                    self.data["HEAHEA"]["CouOfDisCodHEA55"] = next_line
                    break
            # –ò–ª–∏ –±–∞—Ä–∞—ò –¥–∏—Ä–µ–∫—Ç–Ω–æ MK –∞–∫–æ –µ –≤–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            elif line == 'MK' and i > self.data_start_index + 15:
                # –ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ –µ –≤–æ –ø—Ä–∞–≤–∏–ª–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç (–Ω–µ –µ TIN)
                prev_line = self.get_line_safe(i - 1)
                if not prev_line.startswith('MK') and not prev_line.isdigit():
                    if "CouOfDisCodHEA55" not in self.data["HEAHEA"]:
                        self.data["HEAHEA"]["CouOfDisCodHEA55"] = line
        
        # Country of destination code - –±–∞—Ä–∞—ò –∑–µ–º—ò–∞ –∏ –∫–æ–¥
        # –û–±–∏—á–Ω–æ –µ –≤–æ —Ñ–æ—Ä–º–∞—Ç: –§–†–ê–ù–¶–ò–à–ê / FR –∏–ª–∏ GERMANY / DE
        country_names = ['–§–†–ê–ù–¶–ò–à–ê', '–ì–ï–†–ú–ê–ù–ò–à–ê', '–§–†–ê–ù–¶–ï', 'FRANCE', 'GERMANY', 'ITALIA', '–ò–¢–ê–õ–ò–à–ê']
        for i in range(self.data_start_index, min(len(self.lines), self.data_start_index + 50)):
            line = self.lines[i].strip()
            for country in country_names:
                if country in line:
                    # –ë–∞—Ä–∞—ò –∫–æ–¥ –≤–æ —Å–ª–µ–¥–Ω–∏—Ç–µ –Ω–µ–∫–æ–ª–∫—É –ª–∏–Ω–∏–∏
                    for j in range(i + 1, min(len(self.lines), i + 5)):
                        code_line = self.lines[j].strip()
                        if re.match(r'^[A-Z]{2}$', code_line) and code_line != 'MK':
                            self.data["HEAHEA"]["CouOfDesCodHEA30"] = code_line
                            break
                    if "CouOfDesCodHEA30" in self.data["HEAHEA"]:
                        break
            if "CouOfDesCodHEA30" in self.data["HEAHEA"]:
                break
        
        # Container indicator - –±–∞—Ä–∞—ò 0 –∏–ª–∏ 1 –≤–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ –≤–æ–∑–∏–ª–æ
        # –û–±–∏—á–Ω–æ –µ –ø–æ–º–µ—ì—É –Ω–∞—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç–∞ –∏ —É—Å–ª–æ–≤–∏—Ç–µ –Ω–∞ –∏—Å–ø–æ—Ä–∞–∫–∞ (CPT, CIF, FOB...)
        delivery_terms = ['CPT', 'CIF', 'FOB', 'EXW', 'FCA', 'DAP']
        for i in range(self.data_start_index, min(len(self.lines), self.data_start_index + 50)):
            line = self.lines[i].strip()
            if line in ['0', '1']:
                next_idx, next_line = self.find_next_nonempty_line(i + 1, 3)
                if next_line in delivery_terms:
                    self.data["HEAHEA"]["ConIndHEA96"] = line
                    break
        
        # Declaration place - –±–∞—Ä–∞—ò 4-—Ü–∏—Ñ—Ä–µ–Ω –∫–æ–¥ –∏ –∏–º–µ
        # –û–±–∏—á–Ω–æ –µ –≤–æ —Ñ–æ—Ä–º–∞—Ç: 2031 / –¢–ê–ë–ê–ù–û–í–¶–ï-–ü–ê–¢–ù. –∏–ª–∏ —Å–ª–∏—á–Ω–æ
        for i in range(self.data_start_index, min(len(self.lines), self.data_start_index + 50)):
            line = self.lines[i].strip()
            if re.match(r'^\d{4}$', line):
                next_idx, next_line = self.find_next_nonempty_line(i + 1, 2)
                if next_line and len(next_line) > 3 and not next_line.isdigit():
                    self.data["HEAHEA"]["DecPlaHEA394"] = f"{line} {next_line}"
                    break
    
    def extract_traexpex1(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –∏—Å–ø—Ä–∞—ú–∞—á–æ—Ç (TRAEXPEX1)"""
        # TIN - –¥–∞–Ω–æ—á–µ–Ω –±—Ä–æ—ò (MK + 13 —Ü–∏—Ñ—Ä–∏ –∏–ª–∏ –¥—Ä—É–≥ —Ñ–æ—Ä–º–∞—Ç)
        tin_pattern = r'^([A-Z]{2}\d{13})$'
        for i in range(self.data_start_index, min(len(self.lines), self.data_start_index + 20)):
            line = self.lines[i].strip()
            match = re.match(tin_pattern, line)
            if match:
                self.data["TRAEXPEX1"]["TINEX159"] = match.group(1)
                # –°–ª–µ–¥–Ω–∞—Ç–∞ –ª–∏–Ω–∏—ò–∞ –µ –æ–±–∏—á–Ω–æ –∏–º–µ—Ç–æ
                next_idx, next_line = self.find_next_nonempty_line(i + 1, 2)
                if next_line:
                    self.data["TRAEXPEX1"]["NamEX17"] = next_line
                # –£—à—Ç–µ —Å–ª–µ–¥–Ω–∞—Ç–∞ –ª–∏–Ω–∏—ò–∞ –µ –∞–¥—Ä–µ—Å–∞—Ç–∞
                next_idx2, next_line2 = self.find_next_nonempty_line(next_idx + 1, 2)
                if next_line2 and ('—É–ª.' in next_line2 or '–±—É–ª.' in next_line2 or 'str.' in next_line2.lower()):
                    self.data["TRAEXPEX1"]["StrAndNumEX122"] = next_line2
                    # –ò–∑–≤–ª–µ—á–∏ –≥—Ä–∞–¥ –æ–¥ –∞–¥—Ä–µ—Å–∞—Ç–∞
                    if ',' in next_line2:
                        city = next_line2.split(',')[-1].strip()
                        self.data["TRAEXPEX1"]["CitEX124"] = city
                break
        
        # –ü–æ—à—Ç–µ–Ω—Å–∫–∏ –∫–æ–¥ - –æ–±–∏—á–Ω–æ None –∑–∞ –ú–ö
        self.data["TRAEXPEX1"]["PosCodEX123"] = None
        
        # –ó–µ–º—ò–∞ - –∑–µ–º–∏ —ò–∞ –æ–¥ TIN, –Ω–æ –∫–æ—Ä–∏—Å—Ç–∏ –∫–∏—Ä–∏–ª–∏—Ü–∞ –∑–∞ MK
        if "TINEX159" in self.data["TRAEXPEX1"]:
            tin = self.data["TRAEXPEX1"]["TINEX159"]
            country_code = tin[:2]
            if country_code == "MK":
                self.data["TRAEXPEX1"]["CouEX125"] = "–ú–ö"  # –ö–∏—Ä–∏–ª–∏—Ü–∞
            else:
                self.data["TRAEXPEX1"]["CouEX125"] = country_code
    
    def extract_traconce1(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –ø—Ä–∏–º–∞—á–æ—Ç (TRACONCE1)"""
        # –ü—Ä–∏–º–∞—á–æ—Ç –µ –ü–†–ï–î —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏–æ—Ç –±—Ä–æ—ò
        # –†–µ–¥–æ—Å–ª–µ–¥: –ò–ú–ï (-3) -> –ì–†–ê–î (-2) -> –ó–ï–ú–à–ê (-1) -> –†–ï–§–ï–†–ï–ù–¢–ï–ù –ë–†–û–à (0)
        
        # –ë–∞—Ä–∞—ò —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–µ–Ω –±—Ä–æ—ò (4-7 —Ü–∏—Ñ—Ä–∏)
        ref_pattern = r'^\d{4,7}$'
        for i in range(self.data_start_index + 5, min(len(self.lines), self.data_start_index + 30)):
            line = self.lines[i].strip()
            if re.match(ref_pattern, line) and not line.startswith('MK'):
                # –û–≤–∞ –µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏–æ—Ç –±—Ä–æ—ò
                # –ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ 1 –ª–∏–Ω–∏—ò–∞ –ü–†–ï–î –µ –∑–µ–º—ò–∞ –∫–æ–¥ (2-–±—É–∫–≤–∏)
                if i >= 1:
                    country_line = self.lines[i - 1].strip()
                    if re.match(r'^[A-Z]{2}$', country_line) and country_line not in ['MK', '–ú–ö']:
                        self.data["TRACONCE1"]["CouCE125"] = country_line
                        
                        # –ê–¥—Ä–µ—Å–∞ –µ 2 –ª–∏–Ω–∏–∏ –ü–†–ï–î —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏–æ—Ç –±—Ä–æ—ò
                        if i >= 2:
                            address_line = self.lines[i - 2].strip()
                            if address_line and len(address_line) > 2:
                                self.data["TRACONCE1"]["StrAndNumCE122"] = address_line
                                
                                # –ò–∑–≤–ª–µ—á–∏ –ø–æ—à—Ç–µ–Ω—Å–∫–∏ –∫–æ–¥ –∏ –≥—Ä–∞–¥ –æ–¥ –∞–¥—Ä–µ—Å–∞
                                # –§–æ—Ä–º–∞—Ç: "–§–†–ï–à–°–ò–ú–ê–¢ –ë–ê–°–ï –§–ò–¶ 71210 –°—Ç.–ï—É—Å–µ–±–µ"
                                postal_match = re.search(r'(\d{4,6})\s+([^\n]+)$', address_line)
                                if postal_match:
                                    self.data["TRACONCE1"]["PosCodCE123"] = postal_match.group(1)
                                    self.data["TRACONCE1"]["CitCE124"] = postal_match.group(2).strip()
                                else:
                                    self.data["TRACONCE1"]["CitCE124"] = address_line
                        
                        # –ò–º–µ –µ 3 –ª–∏–Ω–∏–∏ –ü–†–ï–î —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏–æ—Ç –±—Ä–æ—ò
                        if i >= 3:
                            name_line = self.lines[i - 3].strip()
                            if name_line and len(name_line) > 5:
                                self.data["TRACONCE1"]["NamCE17"] = name_line
                        
                        # TIN –º–æ–∂–µ –¥–∞ –µ –ø–æ—Å–ª–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏–æ—Ç –±—Ä–æ—ò
                        if i + 1 < len(self.lines):
                            tin_line = self.lines[i + 1].strip()
                            if re.match(r'^[A-Z]{2}\d+$', tin_line):
                                self.data["TRACONCE1"]["TINCE159"] = tin_line
                        
                        break
        
        # TIN - –æ–±–∏—á–Ω–æ None –∑–∞ —Å—Ç—Ä–∞–Ω—Å–∫–∏ –ø—Ä–∏–º–∞—á–∏
        self.data["TRACONCE1"]["TINCE159"] = None
    
    def extract_gooitegds(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ —Å—Ç–æ–∫–∏—Ç–µ (GOOITEGDS)"""
        # –ù–∞—ò–¥–∏ –≥–∏ —Å–∏—Ç–µ commodity codes (8-—Ü–∏—Ñ—Ä–µ–Ω–∏ –±—Ä–æ–µ–≤–∏) - —Å–µ–∫–æ—ò –µ –Ω–æ–≤–∞ —Å—Ç–∞–≤–∫–∞
        # –ë–∞—Ä–∞—ò —Å–∞–º–æ –ü–û–°–õ–ï data_start_index –∑–∞ –¥–∞ —Å–µ –∏–∑–±–µ–≥–Ω–∞—Ç —à–∞–±–ª–æ–Ω –∫–æ–¥–æ–≤–∏—Ç–µ
        commodity_positions = []
        search_start = max(self.data_start_index, 100)  # –ü–æ—á–Ω–∏ –±–∞—Ä–∞—ö–µ –ø–æ—Å–ª–µ –ª–∏–Ω–∏—ò–∞ 100
        
        for i in range(search_start, len(self.lines)):
            line = self.lines[i].strip()
            if re.match(r'^\d{8}$', line):
                commodity_positions.append((i, line))
        
        if not commodity_positions:
            # –ê–∫–æ –Ω–µ–º–∞ –Ω–∏–µ–¥–µ–Ω commodity code, –∫—Ä–µ–∏—Ä–∞—ò –ø—Ä–∞–∑–Ω–∞ —Å—Ç–∞–≤–∫–∞
            self.data["GOOITEGDS"].append(self._create_empty_item())
            return
        
        # –ò–∑–≤–ª–µ—á–∏ –≥–∏ —Å–∏—Ç–µ —Å—Ç–∞–≤–∫–∏
        for item_num, (commodity_index, commodity_code) in enumerate(commodity_positions, 1):
            item = {
                "IteNumGDS7": str(item_num),
                "GroMasGDS46": None,
                "GooDesGDS23": "",
                "UNDanGooCodGDI1": None,
                "COMCODGODITM": {
                    "ComNomCMD1": commodity_code
                },
                "PACGS2": [],
                "PRODOCDC2": []
            }
            
            # –û–¥—Ä–µ–¥–∏ –≥–æ –æ–ø—Å–µ–≥–æ—Ç –∑–∞ –æ–≤–∞–∞ —Å—Ç–∞–≤–∫–∞
            next_commodity_index = commodity_positions[item_num][0] if item_num < len(commodity_positions) else len(self.lines)
            item_start = max(0, commodity_index - 30)
            item_end = min(len(self.lines), next_commodity_index)
            # –û–¥—Ä–µ–¥–∏ –≥–æ –æ–ø—Å–µ–≥–æ—Ç –∑–∞ –æ–≤–∞–∞ —Å—Ç–∞–≤–∫–∞
            next_commodity_index = commodity_positions[item_num][0] if item_num < len(commodity_positions) else len(self.lines)
            item_start = max(0, commodity_index - 30)
            item_end = min(len(self.lines), next_commodity_index)
            
            # –û–ø–∏—Å –Ω–∞ —Å—Ç–æ–∫–∞ - –±–∞—Ä–∞—ò –ü–û–°–õ–ï commodity code, –ø–æ—Å–ª–µ "–ü–∞–ª–µ—Ç–∞"
            for i in range(commodity_index, min(commodity_index + 10, item_end)):
                if '–ü–∞–ª–µ—Ç–∞' in self.lines[i] or '–ø–∞–ª–µ—Ç–∞' in self.lines[i].lower():
                    next_idx, desc = self.find_next_nonempty_line(i + 1, 3)
                    if desc and len(desc) > 5:
                        desc = re.sub(r'-1\s+–∫–æ–º\.', '-1–∫–æ–º.', desc)
                        item["GooDesGDS23"] = desc
                    break
            
            # –ê–∫–æ –Ω–µ–º–∞ "–ü–∞–ª–µ—Ç–∞", –±–∞—Ä–∞—ò —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ commodity code
            if not item["GooDesGDS23"]:
                for j in range(commodity_index + 1, min(commodity_index + 5, item_end)):
                    potential_desc = self.lines[j].strip()
                    if len(potential_desc) > 10 and not potential_desc.isdigit() and not re.match(r'^[A-Z]{2}$', potential_desc):
                        item["GooDesGDS23"] = potential_desc
                        break
            
            # –ë—Ä—É—Ç–æ –º–∞—Å–∞ –∏ –ø–∞–∫—É–≤–∞—ö–µ - –±–∞—Ä–∞—ò –≤–æ –æ–ø—Å–µ–≥–æ—Ç –Ω–∞ –æ–≤–∞–∞ —Å—Ç–∞–≤–∫–∞
            package_types = ['PX', 'CT', 'BX', 'PA', 'PK', 'CS', 'CR']
            for i in range(item_start, item_end):
                if self.lines[i].strip() in package_types:
                    num1_idx, num1 = self.find_next_nonempty_line(i + 1, 3)
                    if num1:
                        num2_idx, num2 = self.find_next_nonempty_line(num1_idx + 1, 3)
                        if num2:
                            try:
                                mass = float(num2.replace(',', '.'))
                                item["GroMasGDS46"] = mass
                            except ValueError:
                                pass
                    
                    num_idx, num_packages = self.find_next_nonempty_line(i - 1, 1, backward=True)
                    if num_packages and num_packages.isdigit():
                        package = {
                            "KinOfPacGS23": self.lines[i].strip(),
                            "NumOfPacGS24": num_packages,
                            "MarNumOfPacGS21": None
                        }
                        item["PACGS2"].append(package)
                    break
            
            # Previous documents - –±–∞—Ä–∞—ò –≤–æ —Ü–µ–ª–∏–æ—Ç —Ç–µ–∫—Å—Ç (–∑–∞ —Å–µ–≥–∞ - –ø–æ–¥–æ–±—Ä—É–≤–∞—ö–µ –ø–æ—Ç—Ä–µ–±–Ω–æ)
            # TODO: –¢—Ä–µ–±–∞ –¥–∞ –≥–∏ —Ñ–∏–ª—Ç—Ä–∏—Ä–∞–º–µ —Å–∞–º–æ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ç–µ –∑–∞ –æ–≤–∞–∞ —Å—Ç–∞–≤–∫–∞
            if item_num == 1:  # –°–∞–º–æ –∑–∞ –ø—Ä–≤–∞ —Å—Ç–∞–≤–∫–∞ –∑–µ–º–∏ –≥–∏ —Å–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∏
                doc_pattern = r'(\w+)\(([^\)]+)\)'
                doc_text = ' '.join(self.lines)
                temp_docs = []
                for match in re.finditer(doc_pattern, doc_text):
                    doc_type = match.group(1)
                    doc_ref = match.group(2)
                    if doc_type in ['5010', '5016', '5009', '5007', 'POAN', '5069', 'AUN', '5077', 'T1']:
                        temp_docs.append((doc_type, doc_ref, match.start()))
                
                temp_docs.sort(key=lambda x: x[2])
                seen = set()
                for doc_type, doc_ref, pos in temp_docs:
                    if doc_type == '5007':
                        continue
                    if (doc_type, doc_ref) not in seen:
                        item["PRODOCDC2"].append({
                            "DocTypDC21": doc_type,
                            "DocRefDC23": doc_ref
                        })
                        seen.add((doc_type, doc_ref))
            
            self.data["GOOITEGDS"].append(item)
    
    def _create_empty_item(self):
        """–ö—Ä–µ–∏—Ä–∞ –ø—Ä–∞–∑–Ω–∞ —Å—Ç–∞–≤–∫–∞"""
        return {
            "IteNumGDS7": "1",
            "GroMasGDS46": None,
            "GooDesGDS23": "",
            "UNDanGooCodGDI1": None,
            "COMCODGODITM": {
                "ComNomCMD1": ""
            },
            "PACGS2": [],
            "PRODOCDC2": []
        }
    
    def find_next_nonempty_line(self, start_index: int, max_search: int = 10, backward: bool = False) -> Tuple[int, str]:
        """–ù–∞–æ—ì–∞ —ò–∞ —Å–ª–µ–¥–Ω–∞—Ç–∞/–ø—Ä–µ—Ç—Ö–æ–¥–Ω–∞—Ç–∞ –Ω–µ–ø—Ä–∞–∑–Ω–∞ –ª–∏–Ω–∏—ò–∞"""
        if backward:
            for i in range(start_index, max(0, start_index - max_search), -1):
                line = self.lines[i].strip()
                if line and line not in ['–∞', '–±', '–≤', '–≥']:
                    return i, line
        else:
            for i in range(start_index, min(len(self.lines), start_index + max_search)):
                line = self.lines[i].strip()
                if line and line not in ['–∞', '–±', '–≤', '–≥']:
                    return i, line
        return -1, ""
    
    def extract_all(self) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –≥–∏ —Å–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ PDF"""
        print("üîç –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ —Ç–µ–∫—Å—Ç –æ–¥ PDF...")
        self.extract_text_from_pdf()
        
        print("üîé –ë–∞—Ä–∞—ö–µ –Ω–∞ —Å–µ–∫—Ü–∏—ò–∞—Ç–∞ —Å–æ –ø–æ–¥–∞—Ç–æ—Ü–∏...")
        self.find_data_section()
        print(f"   –ü–æ—á–µ—Ç–æ–∫ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –Ω–∞ –ª–∏–Ω–∏—ò–∞: {self.data_start_index}")
        
        print("üìÑ –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ HEAHEA...")
        self.extract_heahea()
        
        print("üì§ –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –∏—Å–ø—Ä–∞—ú–∞—á (TRAEXPEX1)...")
        self.extract_traexpex1()
        
        print("üì• –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –ø—Ä–∏–º–∞—á (TRACONCE1)...")
        self.extract_traconce1()
        
        print("üì¶ –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ —Å—Ç–æ–∫–∏ (GOOITEGDS)...")
        self.extract_gooitegds()
        
        return self.data
    
    def save_to_json(self, output_path: str):
        """–ó–∞—á—É–≤—É–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –≤–æ JSON —Ñ–∞—ò–ª"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ –ü–æ–¥–∞—Ç–æ—Ü–∏—Ç–µ —Å–µ –∑–∞—á—É–≤–∞–Ω–∏ –≤–æ: {output_path}")
    
    def compare_with_expected(self, expected_path: str):
        """–°–ø–æ—Ä–µ–¥—É–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏—Ç–µ"""
        with open(expected_path, 'r', encoding='utf-8') as f:
            expected = json.load(f)
        
        print("\n" + "=" * 60)
        print("üîç –°–ø–æ—Ä–µ–¥–±–∞ —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏:")
        print("=" * 60)
        
        differences = []
        matches = []
        
        def compare_dict(path, actual, expected):
            if isinstance(expected, dict):
                for key in expected:
                    new_path = f"{path}.{key}" if path else key
                    if key not in actual:
                        differences.append(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Å—É–≤–∞: {new_path}")
                    else:
                        compare_dict(new_path, actual[key], expected[key])
            elif isinstance(expected, list):
                if len(actual) != len(expected):
                    differences.append(f"‚ö†Ô∏è  {path}: –†–∞–∑–ª–∏—á–Ω–∞ –¥–æ–ª–∂–∏–Ω–∞ –Ω–∞ –ª–∏—Å—Ç–∞ (–∏–∑–≤–ª–µ—á–µ–Ω–æ: {len(actual)}, –æ—á–µ–∫—É–≤–∞–Ω–æ: {len(expected)})")
                for i, (a, e) in enumerate(zip(actual, expected)):
                    compare_dict(f"{path}[{i}]", a, e)
            else:
                if actual != expected:
                    differences.append(f"‚ùå {path}: –∏–∑–≤–ª–µ—á–µ–Ω–æ='{actual}' != –æ—á–µ–∫—É–≤–∞–Ω–æ='{expected}'")
                else:
                    matches.append(f"‚úÖ {path}")
        
        compare_dict("", self.data, expected)
        
        if differences:
            print(f"\n‚ö†Ô∏è  –ü—Ä–æ–Ω–∞—ò–¥–µ–Ω–∏ {len(differences)} —Ä–∞–∑–ª–∏–∫–∏:")
            for diff in differences:
                print(diff)
        
        print(f"\n‚úÖ –¢–æ—á–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏: {len(matches)}/{len(matches) + len(differences)}")
        
        if not differences:
            print("\nüéâ –û–¥–ª–∏—á–Ω–æ! –°–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏ —Å–µ —Ç–æ—á–Ω–∏!")
        
        return len(differences) == 0


def main():
    """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞"""
    pdf_path = "ECD341.pdf"
    output_path = "extracted_data_generic.json"
    expected_path = "341_correct example.json"
    
    print("=" * 60)
    print("üöÄ ECD PDF Extractor - Generic Version")
    print("=" * 60)
    
    extractor = ECDExtractorGeneric(pdf_path)
    data = extractor.extract_all()
    extractor.save_to_json(output_path)
    
    # –°–ø–æ—Ä–µ–¥–±–∞ —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏
    is_correct = extractor.compare_with_expected(expected_path)
    
    if is_correct:
        print("\n" + "=" * 60)
        print("‚úÖ –£—Å–ø–µ—à–Ω–æ! –ü–æ–¥–∞—Ç–æ—Ü–∏—Ç–µ —Å–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏ —Ç–æ—á–Ω–æ.")
        print("=" * 60)
    else:
        print("\n" + "=" * 60)
        print("‚ö†Ô∏è  –ò–º–∞ –Ω–µ–∫–æ–∏ —Ä–∞–∑–ª–∏–∫–∏ - –º–æ–∂–µ –¥–∞ —Ç—Ä–µ–±–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–æ —Ç—É–Ω–∏—Ä–∞—ö–µ.")
        print("=" * 60)
        print("\nüìä –ò–∑–≤–ª–µ—á–µ–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏:")
        print(json.dumps(data, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
