#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ECD (Electronic Customs Declaration) PDF Extractor
–°–∫—Ä–∏–ø—Ç–∞ –∑–∞ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ –ï–¶–î PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏
"""

import fitz  # PyMuPDF
import re
import json
from typing import Dict, List, Optional, Any


class ECDExtractor:
    """–ö–ª–∞—Å–∞ –∑–∞ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ –ï–¶–î PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏"""
    
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        self.text = ""
        self.data = {
            "HEAHEA": {},
            "TRAEXPEX1": {},
            "TRACONCE1": {},
            "SEAINFSLI": {
                "SeaNumSLI2": None,
                "SEAIDSID": [{"SeaIdeSID1": ""}]
            },
            "GOOITEGDS": []
        }
    
    def extract_text_from_pdf(self) -> str:
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ —Ç–µ–∫—Å—Ç –æ–¥ PDF –¥–æ–∫—É–º–µ–Ω—Ç"""
        doc = fitz.open(self.pdf_path)
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        self.text = text
        return text
    
    def extract_heahea(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ HEAHEA —Å–µ–∫—Ü–∏—ò–∞—Ç–∞"""
        # Total gross mass - –≤–∫—É–ø–Ω–∞ –º–∞—Å–∞ (–±–∞—Ä–∞—ò —ò–∞ –±—Ä–æ—ò–∫–∞—Ç–∞ —à—Ç–æ –µ —Å–∞–º–∞ –Ω–∞ –ª–∏–Ω–∏—ò–∞ –ø—Ä–µ–¥ "KGM")
        mass_pattern = r'(\d+)\s*\n\s*KGM'
        mass_match = re.search(mass_pattern, self.text)
        if mass_match:
            self.data["HEAHEA"]["TotGroMasHEA307"] = int(mass_match.group(1))
        
        # Identity and nationality of means of transport - —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—ò–∞ –Ω–∞ –≤–æ–∑–∏–ª–æ
        # –û–¥ –ø–æ–ª–µ 21 (–≤—Ç–æ—Ä–∞ –ø–æ—ò–∞–≤–∞ - —Ç–∞–∞ —à—Ç–æ —ò–∞ –º–∏–Ω—É–≤–∞ –≥—Ä–∞–Ω–∏—Ü–∞—Ç–∞)
        vehicle_pattern = r'21\.\s+–†–µ–≥–∏—Å—Ç[^\n]*–≥—Ä–∞–Ω–∏—Ü–∞—Ç?\s*\n([A-Z]{2}\d{4}[A-Z]{2}(?:/[A-Z]{2}\d{4}[A-Z]{2})?)'
        vehicle_match = re.search(vehicle_pattern, self.text)
        if vehicle_match:
            self.data["HEAHEA"]["IdeOfMeaOfTraAtDHEA78"] = vehicle_match.group(1)
        
        # Mode of transport at the border - –∫–æ–¥–æ—Ç –∑–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç (–æ–¥ –ø–æ–ª–µ 25)
        mode_pattern = r'25\.\s+–í–∏–¥\s+–Ω–∞\s+—Ç—Ä–∞–Ω[^\n]*\n(\d)'
        mode_match = re.search(mode_pattern, self.text)
        if mode_match:
            self.data["HEAHEA"]["TraModAtBorHEA76"] = mode_match.group(1)
        
        # Country of dispatch code - –∑–µ–º—ò–∞ –Ω–∞ –∏—Å–ø—Ä–∞—ú–∞—ö–µ (–æ–¥ –ø–æ–ª–µ 15)
        # –ë–∞—Ä–∞—ò "15.–®–∏—Ñ—Ä–∞" –∏ –∑–µ–º–∏ –≥–æ —Å–ª–µ–¥–Ω–∏–æ—Ç —Ä–µ–¥
        dispatch_pattern = r'15\.–®–∏—Ñ—Ä–∞[^\n]*\n([A-Z]{2})'
        dispatch_match = re.search(dispatch_pattern, self.text)
        if dispatch_match:
            self.data["HEAHEA"]["CouOfDisCodHEA55"] = dispatch_match.group(1)
        
        # Country of destination code - –∑–µ–º—ò–∞ –Ω–∞ –¥–µ—Å—Ç–∏–Ω–∞—Ü–∏—ò–∞ (–æ–¥ –ø–æ–ª–µ 17)
        # –ë–∞—Ä–∞—ò –ª–∏–Ω–∏—ò–∞ —Å–æ "17. –ó–µ–º—ò–∞ –Ω–∞ –Ω–∞–º–µ–Ω–∞" –∏ –∑–µ–º–∏ FR –∫–æ—ò –µ –ø–æ–¥–æ–ª—É
        dest_pattern = r'17\.\s+–ó–µ–º—ò–∞\s+–Ω–∞\s+–Ω–∞–º–µ–Ω–∞[^\n]*\n[–∞–±\s]*\n([A-Z]{2})'
        dest_match = re.search(dest_pattern, self.text)
        if dest_match:
            self.data["HEAHEA"]["CouOfDesCodHEA30"] = dest_match.group(1)
        
        # Container indicator (–æ–¥ –ø–æ–ª–µ 19 - –ö–æ–Ω)
        container_pattern = r'19\.–ö–æ–Ω\s+[^\n]*\n(\d)'
        container_match = re.search(container_pattern, self.text)
        if container_match:
            self.data["HEAHEA"]["ConIndHEA96"] = container_match.group(1)
        else:
            self.data["HEAHEA"]["ConIndHEA96"] = "0"
        
        # Declaration place - –º–µ—Å—Ç–æ –Ω–∞ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏—ò–∞ (–æ–¥ –ø–æ–ª–µ 29)
        place_pattern = r'29\.\s+–¶–∞—Ä–∏–Ω–∞—Ä–Ω–∏—Ü–∞[^\n]*\n(\d+)\s*\n([^\n]+?)\s*\n'
        place_match = re.search(place_pattern, self.text)
        if place_match:
            self.data["HEAHEA"]["DecPlaHEA394"] = f"{place_match.group(1)} {place_match.group(2)}"
        
        # Nationality of means of transport crossing the border (–æ–¥ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—ò–∞)
        nat_pattern = r'21\.\s+–†–µ–≥–∏—Å—Ç[^\n]*–≥—Ä–∞–Ω–∏—Ü–∞—Ç?\s*\n([A-Z]{2})\d{4}[A-Z]{2}'
        nat_match = re.search(nat_pattern, self.text)
        if nat_match:
            self.data["HEAHEA"]["NatOfMeaOfTraCroHEA87"] = nat_match.group(1)
    
    def extract_traexpex1(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –∏—Å–ø—Ä–∞—ú–∞—á–æ—Ç (TRAEXPEX1)"""
        # –ë–∞—Ä–∞—ò –≥–æ –¥–µ–ª–æ—Ç —Å–æ –∏—Å–ø—Ä–∞—ú–∞—á (–æ–¥ –ø–æ–ª–µ 2)
        # –ò–º–µ –Ω–∞ –∏—Å–ø—Ä–∞—ú–∞—á - –ª–∏–Ω–∏—ò–∞—Ç–∞ –ø–æ—Å–ª–µ "MK40..."
        exporter_name_pattern = r'MK\d{13}\s*\n([^\n]+)\s*\n—É–ª\.'
        exporter_name_match = re.search(exporter_name_pattern, self.text)
        if exporter_name_match:
            self.data["TRAEXPEX1"]["NamEX17"] = exporter_name_match.group(1).strip()
        
        # TIN - –¥–∞–Ω–æ—á–µ–Ω –±—Ä–æ—ò (–º–∞–∫–µ–¥–æ–Ω—Å–∫–∏ —Ñ–æ—Ä–º–∞—Ç)
        tin_pattern = r'(MK\d{13})'
        tin_match = re.search(tin_pattern, self.text)
        if tin_match:
            self.data["TRAEXPEX1"]["TINEX159"] = tin_match.group(1)
        
        # –ê–¥—Ä–µ—Å–∞ - –ª–∏–Ω–∏—ò–∞ —à—Ç–æ –ø–æ—á–Ω—É–≤–∞ —Å–æ "—É–ª."
        address_pattern = r'(—É–ª\.[^\n]+)'
        address_match = re.search(address_pattern, self.text)
        if address_match:
            self.data["TRAEXPEX1"]["StrAndNumEX122"] = address_match.group(1).strip()
        
        # –ì—Ä–∞–¥ - –±–∞—Ä–∞—ò "–°–∫–æ–ø—ò–µ" –≤–æ –∞–¥—Ä–µ—Å–∞—Ç–∞
        if "–°–∫–æ–ø—ò–µ" in self.text:
            self.data["TRAEXPEX1"]["CitEX124"] = "–°–∫–æ–ø—ò–µ"
        
        # –ü–æ—à—Ç–µ–Ω—Å–∫–∏ –∫–æ–¥
        self.data["TRAEXPEX1"]["PosCodEX123"] = None
        
        # –ó–µ–º—ò–∞
        self.data["TRAEXPEX1"]["CouEX125"] = "–ú–ö"
    
    def extract_traconce1(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –ø—Ä–∏–º–∞—á–æ—Ç (TRACONCE1)"""
        # –ë–∞—Ä–∞—ò –≥–æ –¥–µ–ª–æ—Ç —Å–æ –ø—Ä–∏–º–∞—á (–æ–¥ –ø–æ–ª–µ 8)
        # –ò–º–µ –Ω–∞ –ø—Ä–∏–º–∞—á - –ø–æ—Å–ª–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏–æ—Ç –±—Ä–æ—ò
        consignee_name_pattern = r'\d{6}\s*\n([^\n]+&[^\n]+)\s*\n([^\n]+71210[^\n]+)'
        consignee_name_match = re.search(consignee_name_pattern, self.text)
        if consignee_name_match:
            self.data["TRACONCE1"]["NamCE17"] = consignee_name_match.group(1).strip()
            self.data["TRACONCE1"]["StrAndNumCE122"] = consignee_name_match.group(2).strip()
        
        # TIN
        self.data["TRACONCE1"]["TINCE159"] = None
        
        # –ì—Ä–∞–¥ –∏ –ø–æ—à—Ç–µ–Ω—Å–∫–∏ –∫–æ–¥ - –æ–¥ –∞–¥—Ä–µ—Å–∞—Ç–∞
        city_pattern = r'71210\s+([^\n]+)'
        city_match = re.search(city_pattern, self.text)
        if city_match:
            self.data["TRACONCE1"]["CitCE124"] = city_match.group(1).strip()
            self.data["TRACONCE1"]["PosCodCE123"] = "71210"
        
        # –ó–µ–º—ò–∞
        self.data["TRACONCE1"]["CouCE125"] = "FR"
    
    def extract_gooitegds(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ —Å—Ç–æ–∫–∏—Ç–µ (GOOITEGDS)"""
        # –ö—Ä–µ–∏—Ä–∞—ò –µ–¥–µ–Ω –µ–ª–µ–º–µ–Ω—Ç –∑–∞ —Å—Ç–æ–∫–∏
        item = {
            "IteNumGDS7": "1",
            "GroMasGDS46": None,
            "GooDesGDS23": "",
            "UNDanGooCodGDI1": None,
            "COMCODGODITM": {
                "ComNomCMD1": ""
            },
            "PACGS2": [],
            "PRODOCDC2": []
        }
        
        # –ú–∞—Å–∞ –Ω–∞ —Å—Ç–æ–∫–∞ (–æ–¥ –ø–æ–ª–µ 35 - –±—Ä—É—Ç–æ –º–∞—Å–∞)
        item_mass_pattern = r'35\.\s+–ë—Ä—É—Ç–æ\s+–º–∞—Å–∞[^\n]*\n[^\n]*\n[^\n]*\n(\d+\.?\d*)\s*\n'
        item_mass_match = re.search(item_mass_pattern, self.text)
        if item_mass_match:
            mass_str = item_mass_match.group(1).replace(',', '.')
            item["GroMasGDS46"] = float(mass_str)
        
        # –û–ø–∏—Å –Ω–∞ —Å—Ç–æ–∫–∞ (–æ–¥ –ø–æ–ª–µ 31)
        desc_pattern = r'–ü–∞–ª–µ—Ç–∞\s*\n(–í–∏—Ç–ª–æ[^\n]+)'
        desc_match = re.search(desc_pattern, self.text)
        if desc_match:
            item["GooDesGDS23"] = desc_match.group(1).strip()
        
        # Commodity code (–æ–¥ –ø–æ–ª–µ 33 - 8-—Ü–∏—Ñ—Ä–µ–Ω —Ç–∞—Ä–∏—Ñ–µ–Ω –±—Ä–æ—ò)
        commodity_pattern = r'32\.–†\.–±—Ä\.[^\n]*\n33[^\n]*\n[^\n]*\n[^\n]*\n(\d{8})'
        commodity_match = re.search(commodity_pattern, self.text)
        if commodity_match:
            item["COMCODGODITM"]["ComNomCMD1"] = commodity_match.group(1)
        
        # Packages - –ø–∞–∫—É–≤–∞—ö–∞ (–±–∞—Ä–∞—ò PX –∏ –±—Ä–æ—ò –Ω–∞ –∫–æ–ª–µ—Ç–∏)
        package = {
            "KinOfPacGS23": "PX",
            "NumOfPacGS24": "7",
            "MarNumOfPacGS21": None
        }
        
        # –ë–∞—Ä–∞—ò "7 PX" –∏–ª–∏ —Å–ª–∏—á–Ω–æ
        pack_pattern = r'(\d+)\s*\n\s*([A-Z]{2})\s*\n'
        pack_match = re.search(pack_pattern, self.text)
        if pack_match:
            package["NumOfPacGS24"] = pack_match.group(1)
            package["KinOfPacGS23"] = pack_match.group(2)
        
        item["PACGS2"].append(package)
        
        # Previous documents - –ø—Ä–µ—Ç—Ö–æ–¥–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏ (–æ–¥ –ø–æ–ª–µ 40)
        # –ü—Ä–∏–º–µ—Ä: 5010(011/2022); 5016(0002826); ...
        
        # –§–∞–∫—Ç—É—Ä–∞ 5010
        invoice_pattern = r'5010\(([^\)]+)\)'
        invoice_match = re.search(invoice_pattern, self.text)
        if invoice_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "5010",
                "DocRefDC23": invoice_match.group(1)
            })
        
        # –¶–∞—Ä–∏–Ω—Å–∫–∞ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏—ò–∞ 5016
        customs_pattern = r'5016\(([^\)]+)\)'
        customs_match = re.search(customs_pattern, self.text)
        if customs_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "5016",
                "DocRefDC23": customs_match.group(1)
            })
        
        # –î–∞—Ç—É–º 5009
        date_pattern = r'5009\(([^\)]+)\)'
        date_match = re.search(date_pattern, self.text)
        if date_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "5009",
                "DocRefDC23": date_match.group(1)
            })
        
        # POAN –¥–æ–∫—É–º–µ–Ω—Ç
        poan_pattern = r'POAN\(([^\)]+)\)'
        poan_match = re.search(poan_pattern, self.text)
        if poan_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "POAN",
                "DocRefDC23": poan_match.group(1)
            })
        
        # 5069 –¥–æ–∫—É–º–µ–Ω—Ç
        doc_5069_pattern = r'5069\(([^\)]+)\)'
        doc_5069_match = re.search(doc_5069_pattern, self.text)
        if doc_5069_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "5069",
                "DocRefDC23": doc_5069_match.group(1)
            })
        
        # –ê–£–ù –¥–æ–∫—É–º–µ–Ω—Ç
        aun_pattern = r'AUN\(([^\)]+)\)'
        aun_match = re.search(aun_pattern, self.text)
        if aun_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "AUN",
                "DocRefDC23": aun_match.group(1)
            })
        
        # 5077 –¥–æ–∫—É–º–µ–Ω—Ç
        doc_5077_pattern = r'5077\(([^\)]+)\)'
        doc_5077_match = re.search(doc_5077_pattern, self.text)
        if doc_5077_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "5077",
                "DocRefDC23": doc_5077_match.group(1)
            })
        
        self.data["GOOITEGDS"].append(item)
    
    def extract_all(self) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –≥–∏ —Å–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ PDF"""
        print("üîç –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ —Ç–µ–∫—Å—Ç –æ–¥ PDF...")
        self.extract_text_from_pdf()
        
        print("üìÑ –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ HEAHEA...")
        self.extract_heahea()
        
        print("üì§ –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –∏—Å–ø—Ä–∞—ú–∞—á (TRAEXPEX1)...")
        self.extract_traexpex1()
        
        print("üì• –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –ø—Ä–∏–º–∞—á (TRACONCE1)...")
        self.extract_traconce1()
        
        print("üì¶ –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ —Å—Ç–æ–∫–∏ (GOOITEGDS)...")
        self.extract_gooitegds()
        
        return self.data
    
    def save_to_json(self, output_path: str):
        """–ó–∞—á—É–≤—É–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –≤–æ JSON —Ñ–∞—ò–ª"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ –ü–æ–¥–∞—Ç–æ—Ü–∏—Ç–µ —Å–µ –∑–∞—á—É–≤–∞–Ω–∏ –≤–æ: {output_path}")
    
    def compare_with_expected(self, expected_path: str):
        """–°–ø–æ—Ä–µ–¥—É–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏—Ç–µ"""
        with open(expected_path, 'r', encoding='utf-8') as f:
            expected = json.load(f)
        
        print("\n" + "=" * 60)
        print("üîç –°–ø–æ—Ä–µ–¥–±–∞ —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏:")
        print("=" * 60)
        
        differences = []
        
        def compare_dict(path, actual, expected):
            if isinstance(expected, dict):
                for key in expected:
                    new_path = f"{path}.{key}" if path else key
                    if key not in actual:
                        differences.append(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Å—É–≤–∞: {new_path}")
                    else:
                        compare_dict(new_path, actual[key], expected[key])
            elif isinstance(expected, list):
                if len(actual) != len(expected):
                    differences.append(f"‚ö†Ô∏è  {path}: –†–∞–∑–ª–∏—á–Ω–∞ –¥–æ–ª–∂–∏–Ω–∞ –Ω–∞ –ª–∏—Å—Ç–∞ (–∏–∑–≤–ª–µ—á–µ–Ω–æ: {len(actual)}, –æ—á–µ–∫—É–≤–∞–Ω–æ: {len(expected)})")
                for i, (a, e) in enumerate(zip(actual, expected)):
                    compare_dict(f"{path}[{i}]", a, e)
            else:
                if actual != expected:
                    differences.append(f"‚ùå {path}: –∏–∑–≤–ª–µ—á–µ–Ω–æ='{actual}' != –æ—á–µ–∫—É–≤–∞–Ω–æ='{expected}'")
                else:
                    print(f"‚úÖ {path}: {actual}")
        
        compare_dict("", self.data, expected)
        
        if differences:
            print("\n‚ö†Ô∏è  –ü—Ä–æ–Ω–∞—ò–¥–µ–Ω–∏ —Ä–∞–∑–ª–∏–∫–∏:")
            for diff in differences:
                print(diff)
        else:
            print("\n‚úÖ –°–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏ —Å–µ —Ç–æ—á–Ω–∏!")
        
        return len(differences) == 0


def main():
    """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞"""
    pdf_path = "ECD341.pdf"
    output_path = "extracted_data.json"
    expected_path = "341_correct example.json"
    
    print("=" * 60)
    print("üöÄ ECD PDF Extractor - –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏")
    print("=" * 60)
    
    extractor = ECDExtractor(pdf_path)
    data = extractor.extract_all()
    extractor.save_to_json(output_path)
    
    print("\n" + "=" * 60)
    print("üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏:")
    print("=" * 60)
    print(json.dumps(data, ensure_ascii=False, indent=2))
    
    # –°–ø–æ—Ä–µ–¥–±–∞ —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏
    extractor.compare_with_expected(expected_path)


if __name__ == "__main__":
    main()
