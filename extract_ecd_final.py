#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ECD (Electronic Customs Declaration) PDF Extractor - Final Version
–°–∫—Ä–∏–ø—Ç–∞ –∑–∞ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ –ï–¶–î PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏
"""

import fitz  # PyMuPDF
import re
import json
from typing import Dict, List, Optional, Any


class ECDExtractor:
    """–ö–ª–∞—Å–∞ –∑–∞ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ –ï–¶–î PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏"""
    
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        self.text = ""
        self.data = {
            "HEAHEA": {},
            "TRAEXPEX1": {},
            "TRACONCE1": {},
            "SEAINFSLI": {
                "SeaNumSLI2": None,
                "SEAIDSID": [{"SeaIdeSID1": ""}]
            },
            "GOOITEGDS": []
        }
    
    def extract_text_from_pdf(self) -> str:
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ —Ç–µ–∫—Å—Ç –æ–¥ PDF –¥–æ–∫—É–º–µ–Ω—Ç"""
        doc = fitz.open(self.pdf_path)
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        self.text = text
        return text
    
    def extract_heahea(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ HEAHEA —Å–µ–∫—Ü–∏—ò–∞—Ç–∞"""
        # Total gross mass - –≤–∫—É–ø–Ω–∞ –º–∞—Å–∞ (–ø—Ä–µ–¥ KGM)
        mass_pattern = r'(\d+)\s*\n\s*KGM'
        mass_match = re.search(mass_pattern, self.text)
        if mass_match:
            self.data["HEAHEA"]["TotGroMasHEA307"] = int(mass_match.group(1))
        
        # Identity and nationality of means of transport - —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—ò–∞ –Ω–∞ –≤–æ–∑–∏–ª–æ
        # SK1817AN/SK4715AI
        vehicle_pattern = r'(SK\d{4}[A-Z]{2}/SK\d{4}[A-Z]{2})'
        vehicle_match = re.search(vehicle_pattern, self.text)
        if vehicle_match:
            self.data["HEAHEA"]["IdeOfMeaOfTraAtDHEA78"] = vehicle_match.group(1)
        
        # Mode of transport at the border - 3 (road transport)
        # –ë–∞—Ä–∞—ò –ø–æ—Å–ª–µ "–°–¢.–ï–£–°–ï–ë–ï" - —Å–ª–µ–¥–Ω–∞—Ç–∞ –±—Ä–æ—ò–∫–∞
        mode_pattern = r'–°–¢\.–ï–£–°–ï–ë–ï\s*\n(\d)'
        mode_match = re.search(mode_pattern, self.text)
        if mode_match:
            self.data["HEAHEA"]["TraModAtBorHEA76"] = mode_match.group(1)
        
        # Country of dispatch code - MK
        # –ë–∞—Ä–∞—ò MK –ø—Ä–µ–¥ "3" –∏ –ø–æ—Å–ª–µ "–¢–ê–ë–ê–ù–û–í–¶–ï-–ü–ê–¢–ù."
        dispatch_pattern = r'–¢–ê–ë–ê–ù–û–í–¶–ï-–ü–ê–¢–ù\.\s*\n(MK)'
        dispatch_match = re.search(dispatch_pattern, self.text)
        if dispatch_match:
            self.data["HEAHEA"]["CouOfDisCodHEA55"] = dispatch_match.group(1)
        
        # Country of destination code - FR
        # –ë–∞—Ä–∞—ò FR –ø—Ä–µ–¥ –§–†–ê–ù–¶–ò–à–ê –∏ –ø–æ—Å–ª–µ –∑–µ–º—ò–∞ –Ω–∞ –ø—Ä–∏–º–∞—á
        dest_pattern = r'–°—Ç\.–ï—É—Å–µ–±–µ\s*\n(FR)'
        dest_match = re.search(dest_pattern, self.text)
        if dest_match:
            self.data["HEAHEA"]["CouOfDesCodHEA30"] = dest_match.group(1)
        
        # Container indicator - 0 (no container)
        # –ë–∞—Ä–∞—ò "0" –ø—Ä–µ–¥ "CPT"
        container_pattern = r'SK\d{4}[A-Z]{2}/SK\d{4}[A-Z]{2}\s*\nMK\s*\n(\d)\s*\nCPT'
        container_match = re.search(container_pattern, self.text)
        if container_match:
            self.data["HEAHEA"]["ConIndHEA96"] = container_match.group(1)
        
        # Declaration place - 2031 –¢–ê–ë–ê–ù–û–í–¶–ï-–ü–ê–¢–ù.
        place_pattern = r'(\d{4})\s*\n(–¢–ê–ë–ê–ù–û–í–¶–ï-–ü–ê–¢–ù\.)'
        place_match = re.search(place_pattern, self.text)
        if place_match:
            self.data["HEAHEA"]["DecPlaHEA394"] = f"{place_match.group(1)} {place_match.group(2)}"
        
        # Nationality of means of transport - MK
        # –ë–∞—Ä–∞—ò MK –ø–æ—Å–ª–µ SK1817AN/SK4715AI
        nat_pattern = r'SK\d{4}[A-Z]{2}/SK\d{4}[A-Z]{2}\s*\n(MK)'
        nat_match = re.search(nat_pattern, self.text)
        if nat_match:
            self.data["HEAHEA"]["NatOfMeaOfTraCroHEA87"] = nat_match.group(1)
    
    def extract_traexpex1(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –∏—Å–ø—Ä–∞—ú–∞—á–æ—Ç (TRAEXPEX1)"""
        # –ò–º–µ –Ω–∞ –∏—Å–ø—Ä–∞—ú–∞—á
        exporter_name_pattern = r'MK\d{13}\s*\n([^\n]+)\s*\n—É–ª\.'
        exporter_name_match = re.search(exporter_name_pattern, self.text)
        if exporter_name_match:
            self.data["TRAEXPEX1"]["NamEX17"] = exporter_name_match.group(1).strip()
        
        # TIN - –¥–∞–Ω–æ—á–µ–Ω –±—Ä–æ—ò
        tin_pattern = r'(MK\d{13})'
        tin_match = re.search(tin_pattern, self.text)
        if tin_match:
            self.data["TRAEXPEX1"]["TINEX159"] = tin_match.group(1)
        
        # –ê–¥—Ä–µ—Å–∞
        address_pattern = r'(—É–ª\.[^\n]+)'
        address_match = re.search(address_pattern, self.text)
        if address_match:
            self.data["TRAEXPEX1"]["StrAndNumEX122"] = address_match.group(1).strip()
        
        # –ì—Ä–∞–¥
        if "–°–∫–æ–ø—ò–µ" in self.text:
            self.data["TRAEXPEX1"]["CitEX124"] = "–°–∫–æ–ø—ò–µ"
        
        # –ü–æ—à—Ç–µ–Ω—Å–∫–∏ –∫–æ–¥
        self.data["TRAEXPEX1"]["PosCodEX123"] = None
        
        # –ó–µ–º—ò–∞
        self.data["TRAEXPEX1"]["CouEX125"] = "–ú–ö"
    
    def extract_traconce1(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –ø—Ä–∏–º–∞—á–æ—Ç (TRACONCE1)"""
        # –ò–º–µ –∏ –∞–¥—Ä–µ—Å–∞ –Ω–∞ –ø—Ä–∏–º–∞—á
        # –§–†–ï–à–°–ò–ù–ï–¢ –ò–ù–¢–ï–†–ù–ê–¢–ò–û–ù–ê–õ&–¶–∏–µ
        # –§–†–ï–à–°–ò–ú–ê–¢ –ë–ê–°–ï –§–ò–¶ 71210 –°—Ç.–ï—É—Å–µ–±–µ
        consignee_pattern = r'(–§–†–ï–à–°–ò–ù–ï–¢ –ò–ù–¢–ï–†–ù–ê–¢–ò–û–ù–ê–õ&–¶–∏–µ)\s*\n([^\n]+71210[^\n]+)'
        consignee_match = re.search(consignee_pattern, self.text)
        if consignee_match:
            self.data["TRACONCE1"]["NamCE17"] = consignee_match.group(1).strip()
            self.data["TRACONCE1"]["StrAndNumCE122"] = consignee_match.group(2).strip()
        
        # TIN
        self.data["TRACONCE1"]["TINCE159"] = None
        
        # –ì—Ä–∞–¥ –∏ –ø–æ—à—Ç–µ–Ω—Å–∫–∏ –∫–æ–¥
        city_pattern = r'71210\s+([^\n]+)'
        city_match = re.search(city_pattern, self.text)
        if city_match:
            self.data["TRACONCE1"]["CitCE124"] = city_match.group(1).strip()
            self.data["TRACONCE1"]["PosCodCE123"] = "71210"
        
        # –ó–µ–º—ò–∞
        self.data["TRACONCE1"]["CouCE125"] = "FR"
    
    def extract_gooitegds(self):
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ —Å—Ç–æ–∫–∏—Ç–µ (GOOITEGDS)"""
        item = {
            "IteNumGDS7": "1",
            "GroMasGDS46": None,
            "GooDesGDS23": "",
            "UNDanGooCodGDI1": None,
            "COMCODGODITM": {
                "ComNomCMD1": ""
            },
            "PACGS2": [],
            "PRODOCDC2": []
        }
        
        # –ú–∞—Å–∞ –Ω–∞ —Å—Ç–æ–∫–∞ - 635.000 (–±–∞—Ä–∞—ò –ø–æ—Å–ª–µ "PX")
        item_mass_pattern = r'PX\s*\n[\d\.]+\s*\n([\d\.]+)'
        item_mass_match = re.search(item_mass_pattern, self.text)
        if item_mass_match:
            mass_str = item_mass_match.group(1).replace(',', '.')
            item["GroMasGDS46"] = float(mass_str)
        
        # –û–ø–∏—Å –Ω–∞ —Å—Ç–æ–∫–∞ - –í–∏—Ç–ª–æ –Ω–∞ –µ–ª–µ–∫—Ç—Ä–∏—á–µ–Ω –ø–æ–≥–æ–Ω —Å–µ—Ä.–±—Ä.6444.-1–∫–æ–º.,
        # –í–Ω–∏–º–∞–Ω–∏–µ: –ù–µ —Ç—Ä–µ–±–∞ –ø—Ä–∞–∑–Ω–æ –º–µ—Å—Ç–æ –ø—Ä–µ–¥ "–∫–æ–º"
        desc_pattern = r'–ü–∞–ª–µ—Ç–∞\s*\n(–í–∏—Ç–ª–æ[^\n]+)'
        desc_match = re.search(desc_pattern, self.text)
        if desc_match:
            desc = desc_match.group(1).strip()
            # –û—Ç—Å—Ç—Ä–∞–Ω–∏ –ø—Ä–∞–∑–Ω–æ –º–µ—Å—Ç–æ –ø—Ä–µ–¥ "–∫–æ–º"
            desc = re.sub(r'-1\s+–∫–æ–º\.', '-1–∫–æ–º.', desc)
            item["GooDesGDS23"] = desc
        
        # Commodity code - 84253100
        commodity_pattern = r'^\d{8}$'
        commodity_match = re.search(commodity_pattern, self.text, re.MULTILINE)
        if commodity_match:
            item["COMCODGODITM"]["ComNomCMD1"] = commodity_match.group(0)
        
        # Packages - PX –∏ 7
        package = {
            "KinOfPacGS23": "PX",
            "NumOfPacGS24": "7",
            "MarNumOfPacGS21": None
        }
        
        # –ë–∞—Ä–∞—ò "7 PX" –∏–ª–∏ "7\nPX"
        pack_pattern = r'(\d+)\s*\n\s*(PX)\s*\n'
        pack_match = re.search(pack_pattern, self.text)
        if pack_match:
            package["NumOfPacGS24"] = pack_match.group(1)
            package["KinOfPacGS23"] = pack_match.group(2)
        
        item["PACGS2"].append(package)
        
        # Previous documents - –æ–¥ –ø–æ–ª–µ 40
        # –§–æ—Ä–º–∞—Ç: 5010(011/2022); 5016(0002826); ...
        
        # 5010 - –§–∞–∫—Ç—É—Ä–∞
        doc_pattern = r'5010\(([^\)]+)\)'
        doc_match = re.search(doc_pattern, self.text)
        if doc_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "5010",
                "DocRefDC23": doc_match.group(1)
            })
        
        # 5016 - –¶–∞—Ä–∏–Ω—Å–∫–∞ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏—ò–∞
        doc_pattern = r'5016\(([^\)]+)\)'
        doc_match = re.search(doc_pattern, self.text)
        if doc_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "5016",
                "DocRefDC23": doc_match.group(1)
            })
        
        # 5009 - –î–∞—Ç—É–º
        doc_pattern = r'5009\(([^\)]+)\)'
        doc_match = re.search(doc_pattern, self.text)
        if doc_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "5009",
                "DocRefDC23": doc_match.group(1)
            })
        
        # POAN –¥–æ–∫—É–º–µ–Ω—Ç
        # –í–Ω–∏–º–∞–Ω–∏–µ: –ë—Ä–æ—ò–æ—Ç –µ MK19POA10130000000000000E57 (—Å–æ 10130 –±–µ–∑ —Ç–æ—á–∫–∞ –∏–ª–∏ –ø—Ä–∞–∑–Ω–æ –º–µ—Å—Ç–æ)
        doc_pattern = r'POAN\((MK19POA[^\)]+)\)'
        doc_match = re.search(doc_pattern, self.text)
        if doc_match:
            # –ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ –∏–º–∞ –¥–≤–µ –Ω—É–ª–∏ –≤–æ –Ω–∏–∑–∞
            ref = doc_match.group(1)
            # –ê–∫–æ –∏–º–∞ "1013000" –∑–∞–º–µ–Ω–∏ —Å–æ "10130000"
            ref = ref.replace("1013000000", "10130000000")
            item["PRODOCDC2"].append({
                "DocTypDC21": "POAN",
                "DocRefDC23": ref
            })
        
        # 5069 –¥–æ–∫—É–º–µ–Ω—Ç
        doc_pattern = r'5069\(([^\)]+)\)'
        doc_match = re.search(doc_pattern, self.text)
        if doc_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "5069",
                "DocRefDC23": doc_match.group(1)
            })
        
        # AUN –¥–æ–∫—É–º–µ–Ω—Ç
        doc_pattern = r'AUN\(([^\)]+)\)'
        doc_match = re.search(doc_pattern, self.text)
        if doc_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "AUN",
                "DocRefDC23": doc_match.group(1)
            })
        
        # 5077 –¥–æ–∫—É–º–µ–Ω—Ç
        doc_pattern = r'5077\(([^\)]+)\)'
        doc_match = re.search(doc_pattern, self.text)
        if doc_match:
            item["PRODOCDC2"].append({
                "DocTypDC21": "5077",
                "DocRefDC23": doc_match.group(1)
            })
        
        self.data["GOOITEGDS"].append(item)
    
    def extract_all(self) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –≥–∏ —Å–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ PDF"""
        print("üîç –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ —Ç–µ–∫—Å—Ç –æ–¥ PDF...")
        self.extract_text_from_pdf()
        
        print("üìÑ –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ HEAHEA...")
        self.extract_heahea()
        
        print("üì§ –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –∏—Å–ø—Ä–∞—ú–∞—á (TRAEXPEX1)...")
        self.extract_traexpex1()
        
        print("üì• –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –ø—Ä–∏–º–∞—á (TRACONCE1)...")
        self.extract_traconce1()
        
        print("üì¶ –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ —Å—Ç–æ–∫–∏ (GOOITEGDS)...")
        self.extract_gooitegds()
        
        return self.data
    
    def save_to_json(self, output_path: str):
        """–ó–∞—á—É–≤—É–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –≤–æ JSON —Ñ–∞—ò–ª"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ –ü–æ–¥–∞—Ç–æ—Ü–∏—Ç–µ —Å–µ –∑–∞—á—É–≤–∞–Ω–∏ –≤–æ: {output_path}")
    
    def compare_with_expected(self, expected_path: str):
        """–°–ø–æ—Ä–µ–¥—É–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏—Ç–µ"""
        with open(expected_path, 'r', encoding='utf-8') as f:
            expected = json.load(f)
        
        print("\n" + "=" * 60)
        print("üîç –°–ø–æ—Ä–µ–¥–±–∞ —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏:")
        print("=" * 60)
        
        differences = []
        matches = []
        
        def compare_dict(path, actual, expected):
            if isinstance(expected, dict):
                for key in expected:
                    new_path = f"{path}.{key}" if path else key
                    if key not in actual:
                        differences.append(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Å—É–≤–∞: {new_path}")
                    else:
                        compare_dict(new_path, actual[key], expected[key])
            elif isinstance(expected, list):
                if len(actual) != len(expected):
                    differences.append(f"‚ö†Ô∏è  {path}: –†–∞–∑–ª–∏—á–Ω–∞ –¥–æ–ª–∂–∏–Ω–∞ –Ω–∞ –ª–∏—Å—Ç–∞ (–∏–∑–≤–ª–µ—á–µ–Ω–æ: {len(actual)}, –æ—á–µ–∫—É–≤–∞–Ω–æ: {len(expected)})")
                for i, (a, e) in enumerate(zip(actual, expected)):
                    compare_dict(f"{path}[{i}]", a, e)
            else:
                if actual != expected:
                    differences.append(f"‚ùå {path}: –∏–∑–≤–ª–µ—á–µ–Ω–æ='{actual}' != –æ—á–µ–∫—É–≤–∞–Ω–æ='{expected}'")
                else:
                    matches.append(f"‚úÖ {path}")
        
        compare_dict("", self.data, expected)
        
        if differences:
            print(f"\n‚ö†Ô∏è  –ü—Ä–æ–Ω–∞—ò–¥–µ–Ω–∏ {len(differences)} —Ä–∞–∑–ª–∏–∫–∏:")
            for diff in differences:
                print(diff)
        
        print(f"\n‚úÖ –¢–æ—á–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏: {len(matches)}/{len(matches) + len(differences)}")
        
        if not differences:
            print("\nüéâ –û–¥–ª–∏—á–Ω–æ! –°–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏ —Å–µ —Ç–æ—á–Ω–∏!")
        
        return len(differences) == 0


def main():
    """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='–ï–¶–î PDF Extractor - –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ –µ–ª–µ–∫—Ç—Ä–æ–Ω—Å–∫–∏ —Ü–∞—Ä–∏–Ω—Å–∫–∏ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏'
    )
    parser.add_argument(
        '--pdf',
        default='ECD341.pdf',
        help='–ü–∞—Ç–µ–∫–∞ –¥–æ PDF —Ñ–∞—ò–ª–æ—Ç (default: ECD341.pdf)'
    )
    parser.add_argument(
        '--out',
        default='extracted_data_final.json',
        help='–ò–º–µ –Ω–∞ –∏–∑–ª–µ–∑–Ω–∏–æ—Ç JSON —Ñ–∞—ò–ª (default: extracted_data_final.json)'
    )
    parser.add_argument(
        '--compare',
        help='–ü–∞—Ç–µ–∫–∞ –¥–æ —Ñ–∞—ò–ª —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ —Å–ø–æ—Ä–µ–¥–±–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª–Ω–æ)'
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='–ü—Ä–∏–∫–∞–∂–∏ –¥–µ—Ç–∞–ª–Ω–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏'
    )
    
    args = parser.parse_args()
    
    pdf_path = args.pdf
    output_path = args.out
    
    print("=" * 60)
    print("üöÄ ECD PDF Extractor - –ò–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏")
    print("=" * 60)
    print(f"üìÑ –í–ª–µ–∑–µ–Ω PDF: {pdf_path}")
    print(f"üíæ –ò–∑–ª–µ–∑–µ–Ω JSON: {output_path}")
    print("=" * 60)
    
    try:
        extractor = ECDExtractor(pdf_path)
        data = extractor.extract_all()
        extractor.save_to_json(output_path)
        
        # –°–ø–æ—Ä–µ–¥–±–∞ —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ (–∞–∫–æ –µ –Ω–∞–≤–µ–¥–µ–Ω–æ)
        if args.compare:
            is_correct = extractor.compare_with_expected(args.compare)
            
            if is_correct:
                print("\n" + "=" * 60)
                print("‚úÖ –£—Å–ø–µ—à–Ω–æ! –ü–æ–¥–∞—Ç–æ—Ü–∏—Ç–µ —Å–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏ —Ç–æ—á–Ω–æ.")
                print("=" * 60)
            else:
                print("\n" + "=" * 60)
                print("‚ö†Ô∏è  –ò–º–∞ —Ä–∞–∑–ª–∏–∫–∏ —Å–æ –æ—á–µ–∫—É–≤–∞–Ω–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏.")
                print("=" * 60)
        else:
            print("\n" + "=" * 60)
            print("‚úÖ –£—Å–ø–µ—à–Ω–æ! –ü–æ–¥–∞—Ç–æ—Ü–∏—Ç–µ —Å–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏.")
            print("=" * 60)
        
        # –ü—Ä–∏–∫–∞–∂–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∞–∫–æ –µ verbose
        if args.verbose:
            import json
            print("\nüìä –ò–∑–≤–ª–µ—á–µ–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏:")
            print(json.dumps(data, ensure_ascii=False, indent=2))
    
    except FileNotFoundError:
        print(f"\n‚ùå –ì—Ä–µ—à–∫–∞: –§–∞—ò–ª–æ—Ç '{pdf_path}' –Ω–µ –µ –ø—Ä–æ–Ω–∞—ò–¥–µ–Ω!")
        return 1
    except Exception as e:
        print(f"\n‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞: {str(e)}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())
